{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4 Convolution\n",
    "\n",
    "### Predicting Digits\n",
    "\n",
    "Notes on M.L. Libraries\n",
    "\n",
    "Potential libraries to use:\n",
    "\n",
    "Theano\n",
    "\n",
    "Tensorflow, Google\n",
    "\n",
    "    could remake this in notebook for assignment:\n",
    "    \n",
    "    https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "    \n",
    "Torch/Pytorch, Facebook\n",
    "\n",
    "CNTK(gluon)\n",
    "\n",
    "Keras\n",
    "\n",
    "    pip install --update keras\n",
    "    \n",
    "(more options in c++/cuda)\n",
    "\n",
    "For this project I will be using Keras for data training. For a decent introduction to keras see: https://yashk2810.github.io/Applying-Convolutional-Neural-Network-on-the-MNIST-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 20s 2us/step\n",
      "(10000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "num_train, height, width, depth = X_train.shape # there are 50000 training examples\n",
    "num_test = X_test.shape[0] # there are 10000 test examples\n",
    "num_classes = np.unique(y_train).shape[0] # there are 10 image classes\n",
    "\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train/= 255 # Normalise data to [0, 1] range\n",
    "X_test/= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "\n",
    "inp = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def print_data(testx, testy, m):#m for model\n",
    "    score = m.evaluate(testx, testy, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])#print accuracy    \n",
    "    predictions = m.predict_classes(testx)\n",
    "    Y_t = np.argmax(testy, axis=1)\n",
    "    print(precision_recall_fscore_support(Y_t, predictions))\n",
    "    print(\"Classification\")\n",
    "    print(classification_report(Y_t, predictions))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(Y_t, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                346176    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 347,146\n",
      "Trainable params: 347,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1643 - acc: 0.9517 - val_loss: 0.0658 - val_acc: 0.9789\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 54s 907us/step - loss: 0.0554 - acc: 0.9827 - val_loss: 0.0454 - val_acc: 0.9856\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0376 - acc: 0.9884 - val_loss: 0.0461 - val_acc: 0.9850\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0260 - acc: 0.9916 - val_loss: 0.0516 - val_acc: 0.9836\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0186 - acc: 0.9934 - val_loss: 0.0392 - val_acc: 0.9873\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0440 - val_acc: 0.9871\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0577 - val_acc: 0.9839\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0566 - val_acc: 0.9852\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0577 - val_acc: 0.9851\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0735 - val_acc: 0.9832\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0540 - val_acc: 0.9872\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0637 - val_acc: 0.9866\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0691 - val_acc: 0.9866\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 99s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0852 - val_acc: 0.9847\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0696 - val_acc: 0.9878\n",
      "Test loss: 0.0696159979079\n",
      "Test accuracy: 0.9878\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5913a5971362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m           validation_data=(X_test, Y_test))#removed callbacks=[history]\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#unused code from an example i found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m## Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a07bc50fe0e7>\u001b[0m in \u001b[0;36mprint_data\u001b[0;34m(testx, testy, m)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#print accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mY_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 28 # in each iteration, we consider 28 training examples at once\n",
    "num_epochs = 15 # we iterate 200 times over the entire training set\n",
    "k_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 512 # the FC layer will have 512 neurons\n",
    "pad='same'\n",
    "\n",
    "m1 = Sequential()\n",
    "m1.add(Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1)))\n",
    "BatchNormalization(axis=-1)\n",
    "m1.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "m1.add(Flatten())\n",
    "m1.add(Dense(conv_depth_2, activation='relu'))#neural network layer\n",
    "BatchNormalization()\n",
    "m1.add(Dense(num_classes, activation='softmax'))\n",
    "m1.summary()\n",
    "m1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "m1.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          epochs=num_epochs, verbose=1,\n",
    "          validation_data=(X_test, Y_test))#removed callbacks=[history]\n",
    "\n",
    "\n",
    "#unused code from an example i found\n",
    "## Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "#conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "#conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "#pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "#drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "## Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "#conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "#pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "#drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "## Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "#flat = Flatten()(drop_2)\n",
    "#hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "#out = Dense(num_classes, activation='softmax')(drop_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0696159979079\n",
      "Test accuracy: 0.9878\n",
      "(array([ 0.99388379,  0.9903762 ,  0.98640777,  0.98328417,  0.98680203,\n",
      "        0.98657718,  0.98951782,  0.98737864,  0.99060543,  0.98313492]), array([ 0.99489796,  0.99735683,  0.98449612,  0.99009901,  0.9898167 ,\n",
      "        0.98878924,  0.98538622,  0.98929961,  0.97433265,  0.98216056]), array([ 0.99439062,  0.99385426,  0.98545102,  0.98667982,  0.98830707,\n",
      "        0.98768197,  0.9874477 ,  0.98833819,  0.98240166,  0.9826475 ]), array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       980\n",
      "          1       0.99      1.00      0.99      1135\n",
      "          2       0.99      0.98      0.99      1032\n",
      "          3       0.98      0.99      0.99      1010\n",
      "          4       0.99      0.99      0.99       982\n",
      "          5       0.99      0.99      0.99       892\n",
      "          6       0.99      0.99      0.99       958\n",
      "          7       0.99      0.99      0.99      1028\n",
      "          8       0.99      0.97      0.98       974\n",
      "          9       0.98      0.98      0.98      1009\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 975    0    0    2    0    0    3    0    0    0]\n",
      " [   0 1132    1    1    0    0    0    1    0    0]\n",
      " [   1    1 1016    2    1    0    1    6    3    1]\n",
      " [   0    0    1 1000    0    4    0    2    3    0]\n",
      " [   0    0    2    0  972    0    3    0    0    5]\n",
      " [   0    0    1    7    0  882    2    0    0    0]\n",
      " [   2    4    0    0    3    3  944    0    2    0]\n",
      " [   0    3    6    0    0    0    0 1017    0    2]\n",
      " [   1    1    3    2    3    3    1    2  949    9]\n",
      " [   2    2    0    3    6    2    0    2    1  991]]\n"
     ]
    }
   ],
   "source": [
    "print_data(X_test, Y_test, m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Run\n",
    "\n",
    "For this model I used once convolutional layer with 32 kernels, and one fully connected neural network layer that fed into a softmax output layer. The model came up with a 98.48% accuracy. The model was most often wrong when it came to the digit 9 being predicted as a 4, which to be honest seems like an almost human mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(3, 3, 1, 32)\n",
      "(32,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhoekJoaHpCaGh6Qm/w8iqgOTuFe7vwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39784a54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "#attempt at printing convolved image\n",
    "import matplotlib.pyplot as plt\n",
    "print(X_test.shape)\n",
    "plt.imshow(X_test[42, :, :, 0])\n",
    "#plt.imshow(np.squeeze(X_test[42]), cmap='gray')\n",
    "\n",
    "#con = Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1))\n",
    "tmp = m1.layers[0].get_weights()\n",
    "# JD - tmp is a list of 2 numpy tensors\n",
    "print(type(tmp[0]))\n",
    "print(type(tmp[1]))\n",
    "# JD - the first tensor has 32 3x3 kernels\n",
    "print(tmp[0].shape)\n",
    "# JD - the second tensor just has 32 numbers.\n",
    "print(tmp[1].shape)\n",
    "\n",
    "# JD - we can display one of the kernels as an image like this:\n",
    "plt.imshow(tmp[0][:, :, 0, 0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "np_tmp = np.asarray(tmp)\n",
    "#np_tmp = np.squeeze(np_tmp)\n",
    "print(np_tmp.shape)\n",
    "#print(np_tmp)\n",
    "#tmp = np.expand_dims(tmp, axis=0)\n",
    "#t2 = np.array(tmp, dtype=float)\n",
    "# ->plt.imshow(np_tmp, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code edited from: https://github.com/yashk2810/Visualization-of-Convolutional-Layers/blob/master/Visualizing%20Filters%20Python3%20Theano%20Backend.ipynb\n",
    "def visualize_layer(layer, modl, example_image):\n",
    "    inputs = [K.learning_phase()] + modl.inputs\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(example_image)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "    \n",
    "    n = convolutions.shape[0]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "    \n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(len(convolutions)):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "visualize_layer() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f6d4e2603be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvisualize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: visualize_layer() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "X_example = X_test[42]\n",
    "X_example = np.expand_dims(X_example, axis=0)\n",
    "visualize_layer(m1.layers[0], m1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,989,386\n",
      "Trainable params: 3,989,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0976 - acc: 0.9704 - val_loss: 0.0375 - val_acc: 0.9874\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0339 - acc: 0.9896 - val_loss: 0.0324 - val_acc: 0.9891\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0207 - acc: 0.9934 - val_loss: 0.0291 - val_acc: 0.9903\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0370 - val_acc: 0.9895\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0298 - val_acc: 0.9917\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0425 - val_acc: 0.9891\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0521 - val_acc: 0.9883\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 245s 4ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0517 - val_acc: 0.9900\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0425 - val_acc: 0.9915\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0524 - val_acc: 0.9901\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0605 - val_acc: 0.9898\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0765 - val_acc: 0.9888\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0736 - val_acc: 0.9886\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0668 - val_acc: 0.9886\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0725 - val_acc: 0.9872\n",
      "Test loss: 0.0725123223419\n",
      "Test accuracy: 0.9872\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       980\n",
      "          1       0.99      1.00      0.99      1135\n",
      "          2       0.98      0.99      0.99      1032\n",
      "          3       1.00      0.99      0.99      1010\n",
      "          4       0.98      0.99      0.99       982\n",
      "          5       0.98      0.99      0.98       892\n",
      "          6       1.00      0.99      0.99       958\n",
      "          7       0.98      0.98      0.98      1028\n",
      "          8       0.97      0.99      0.98       974\n",
      "          9       1.00      0.96      0.98      1009\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1130    2    0    0    2    1    0    0    0]\n",
      " [   2    0 1022    0    0    0    0    5    2    1]\n",
      " [   0    0    2  996    0    8    0    1    3    0]\n",
      " [   0    0    1    0  976    0    0    0    3    2]\n",
      " [   0    0    0    4    0  879    1    0    8    0]\n",
      " [   4    2    2    0    1    3  945    0    1    0]\n",
      " [   1    2    9    0    2    0    0 1012    2    0]\n",
      " [   3    0    2    1    2    0    0    2  963    1]\n",
      " [   0    3    0    0   15    5    0    7    6  973]]\n"
     ]
    }
   ],
   "source": [
    "#function for creating simple model\n",
    "#def train_cnn(xt, yt, xtrain, ytrain, c_depth, kern_sizes, padding, layers):# padding='valid' | 'same' and activation='relu'\n",
    "#    model = Sequential()\n",
    "#    input_shape = Input(shape=(height, width, depth))\n",
    "#    model.add(Conv2D(32, (kern_sizes[0], kern_sizes[0]), padding, activation='relu',\n",
    "#                 input_shape=input_shape))\n",
    "\n",
    "batch_size = 28 # in each iteration, we consider 28 training examples at once\n",
    "num_epochs = 15 # we iterate 200 times over the entire training set\n",
    "k_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 512 # the FC layer will have 512 neurons\n",
    "pad='same'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1)))#convolution one\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Conv2D(conv_depth_2, (k_size, k_size), activation='relu', input_shape=(28,28,1)))#convolution 2\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_size, activation='relu'))#neural network layer\n",
    "BatchNormalization()\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          epochs=num_epochs, verbose=1,\n",
    "          validation_data=(X_test, Y_test))#removed callbacks=[history]\n",
    "print_data(X_test, Y_test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
