{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4 Convolution\n",
    "\n",
    "### Predicting Digits\n",
    "\n",
    "Notes on M.L. Libraries\n",
    "\n",
    "Potential libraries to use:\n",
    "\n",
    "Theano\n",
    "\n",
    "Tensorflow, Google\n",
    "\n",
    "    could remake this in notebook for assignment:\n",
    "    \n",
    "    https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "    \n",
    "Torch/Pytorch, Facebook\n",
    "\n",
    "CNTK(gluon)\n",
    "\n",
    "Keras\n",
    "\n",
    "    pip install --update keras\n",
    "    \n",
    "(more options in c++/cuda)\n",
    "\n",
    "For this project I will be using Keras for data training. For a decent introduction to keras see: https://yashk2810.github.io/Applying-Convolutional-Neural-Network-on-the-MNIST-dataset/\n",
    "\n",
    "https://github.com/yashk2810/Visualization-of-Convolutional-Layers/blob/master/Visualizing%20Filters%20Python3%20Theano%20Backend.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "num_train, height, width, depth = X_train.shape # there are 50000 training examples\n",
    "num_test = X_test.shape[0] # there are 10000 test examples\n",
    "num_classes = np.unique(y_train).shape[0] # there are 10 image classes\n",
    "\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train/= 255 # Normalise data to [0, 1] range\n",
    "X_test/= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "\n",
    "inp = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def print_data(testx, testy, m):#m for model\n",
    "    score = m.evaluate(testx, testy, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])#print accuracy    \n",
    "    predictions = m.predict_classes(testx)\n",
    "    Y_t = np.argmax(testy, axis=1)\n",
    "    print(precision_recall_fscore_support(Y_t, predictions))\n",
    "    print(\"Classification\")\n",
    "    print(classification_report(Y_t, predictions))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(Y_t, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                346176    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 347,146\n",
      "Trainable params: 347,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 40s 663us/step - loss: 0.1596 - acc: 0.9538 - val_loss: 0.0654 - val_acc: 0.9784\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 39s 657us/step - loss: 0.0574 - acc: 0.9823 - val_loss: 0.0531 - val_acc: 0.9832\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 39s 655us/step - loss: 0.0388 - acc: 0.9884 - val_loss: 0.0499 - val_acc: 0.9831\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 37s 617us/step - loss: 0.0274 - acc: 0.9912 - val_loss: 0.0416 - val_acc: 0.9879\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 37s 621us/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0478 - val_acc: 0.9858\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 41s 680us/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.0599 - val_acc: 0.9835\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 41s 676us/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0537 - val_acc: 0.9846\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 47s 776us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0580 - val_acc: 0.9852\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 40s 672us/step - loss: 0.0077 - acc: 0.9973 - val_loss: 0.0520 - val_acc: 0.9859\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 44s 734us/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0645 - val_acc: 0.9851\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 43s 710us/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0511 - val_acc: 0.9870\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 48s 794us/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0555 - val_acc: 0.9863\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 44s 741us/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0659 - val_acc: 0.9863\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 48s 802us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0722 - val_acc: 0.9846\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 43s 724us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0661 - val_acc: 0.9873\n",
      "Test loss: 0.0661406944924\n",
      "Test accuracy: 0.9873\n",
      "(array([ 0.98388721,  0.99385965,  0.99604352,  0.99005964,  0.98879837,\n",
      "        0.9789823 ,  0.98849372,  0.97428571,  0.98960499,  0.98795181]), array([ 0.99693878,  0.99823789,  0.97577519,  0.98613861,  0.98879837,\n",
      "        0.99215247,  0.98643006,  0.99513619,  0.97741273,  0.97522299]), array([ 0.99036999,  0.99604396,  0.98580519,  0.98809524,  0.98879837,\n",
      "        0.98552339,  0.98746082,  0.98460058,  0.98347107,  0.98154613]), array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       980\n",
      "          1       0.99      1.00      1.00      1135\n",
      "          2       1.00      0.98      0.99      1032\n",
      "          3       0.99      0.99      0.99      1010\n",
      "          4       0.99      0.99      0.99       982\n",
      "          5       0.98      0.99      0.99       892\n",
      "          6       0.99      0.99      0.99       958\n",
      "          7       0.97      1.00      0.98      1028\n",
      "          8       0.99      0.98      0.98       974\n",
      "          9       0.99      0.98      0.98      1009\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 977    0    0    1    0    0    2    0    0    0]\n",
      " [   0 1133    0    0    0    0    2    0    0    0]\n",
      " [   4    3 1007    1    1    0    1   12    3    0]\n",
      " [   0    0    0  996    0    6    0    6    2    0]\n",
      " [   1    0    0    0  971    1    2    0    1    6]\n",
      " [   0    0    0    4    0  885    2    0    1    0]\n",
      " [   6    2    0    2    2    1  945    0    0    0]\n",
      " [   0    0    2    0    0    0    0 1023    1    2]\n",
      " [   4    1    2    1    1    4    2    3  952    4]\n",
      " [   1    1    0    1    7    7    0    6    2  984]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 28 # in each iteration, we consider 28 training examples at once\n",
    "num_epochs = 15 # we iterate 15 times over the entire training set\n",
    "k_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 512 # the FC layer will have 512 neurons\n",
    "pad='same'\n",
    "\n",
    "m1 = Sequential()\n",
    "m1.add(Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1)))\n",
    "BatchNormalization(axis=-1)\n",
    "m1.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "m1.add(Flatten())\n",
    "m1.add(Dense(conv_depth_2, activation='relu'))#neural network layer\n",
    "BatchNormalization()\n",
    "m1.add(Dense(num_classes, activation='softmax'))\n",
    "m1.summary()\n",
    "m1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "m1.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          epochs=num_epochs, verbose=1,\n",
    "          validation_data=(X_test, Y_test))#removed callbacks=[history]\n",
    "\n",
    "print_data(X_test, Y_test, m1)\n",
    "#unused code from an example i found\n",
    "## Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "#conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "#conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "#pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "#drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "## Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "#conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "#pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "#drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "## Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "#flat = Flatten()(drop_2)\n",
    "#hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "#out = Dense(num_classes, activation='softmax')(drop_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Run\n",
    "\n",
    "For this model I used once convolutional layer with 32 kernels, and one fully connected neural network layer that fed into a softmax output layer. The model came up with a 98.48% accuracy. The model was most often wrong when it came to the digit 9 being predicted as a 4, which to be honest seems like an almost human mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAADFCAYAAAD+BNZ+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMSvaGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30c4d265f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3, 3, 1, 32)\n",
      "<class 'numpy.ndarray'>\n",
      "(32,)\n",
      "[[[[-0.56428576  0.0606623   0.14210002 -0.91838527 -0.76717526  0.04474824\n",
      "    -0.54339558 -0.42050293  0.16667008  0.08130168 -0.7087428  -0.27193767\n",
      "    -0.34644228  0.16770074  0.34822068  0.01211134  0.04579123  0.28536919\n",
      "     0.27042586 -0.90233946 -0.16886547  0.3346729   0.167155    0.11133454\n",
      "    -0.36250833  0.22236921 -0.10721269 -0.02601752 -0.28484732  0.02436283\n",
      "    -0.50142694  0.12491214]]\n",
      "\n",
      "  [[ 0.22786918 -0.53668433  0.21655396 -0.16611862 -0.14533451  0.31253743\n",
      "    -0.46471968  0.13700271  0.35569358  0.39885125  0.19004089  0.11070897\n",
      "    -0.17449316  0.21507016 -0.20264648 -0.0229107   0.06646062 -0.03007865\n",
      "     0.19378439 -0.66733915  0.33019742 -0.02420424  0.11714293  0.42346251\n",
      "    -0.25895736  0.26658624 -0.34046733 -0.01786722  0.1207715   0.27625337\n",
      "    -0.36503097 -0.08176529]]\n",
      "\n",
      "  [[ 0.11990088 -0.17478669 -0.20317233  0.28286347  0.38197744  0.3808226\n",
      "    -0.76372892  0.12546732 -0.15466714  0.35280791  0.27969933  0.2720997\n",
      "     0.37032589 -0.00911372 -0.4309403  -0.00622883 -0.06156478  0.116069\n",
      "     0.10149618 -0.11860939  0.55128932 -0.60605741 -0.25158951  0.04883682\n",
      "    -0.2415266   0.15618236 -0.10565811 -0.03404059  0.16969593 -0.00762731\n",
      "     0.14608705 -0.66315889]]]\n",
      "\n",
      "\n",
      " [[[ 0.25861219  0.37186539  0.17615013 -0.45884386 -0.03170169 -0.13550329\n",
      "    -0.45996195 -0.37536609 -0.3028478  -0.62092018 -0.16668005  0.24985169\n",
      "    -0.65393281 -0.39227447  0.26543513 -0.06448542  0.16012591 -0.23939729\n",
      "    -0.1196362   0.35970852 -0.81839514  0.35671335  0.09412479 -0.54727036\n",
      "    -0.29800618  0.34733087  0.3007454  -0.11283094 -0.09258038 -0.29542282\n",
      "     0.29052204  0.11171219]]\n",
      "\n",
      "  [[ 0.32437268  0.0662307  -0.12726673  0.16402337  0.0914894   0.08519473\n",
      "     0.07344399  0.22628777  0.03995176 -0.72533584 -0.69334418  0.05895085\n",
      "    -0.2782394   0.16803704  0.18132859 -0.09638633  0.15969411 -0.32950824\n",
      "     0.11250681  0.07192746  0.03690526 -0.05606799  0.354619   -0.49530876\n",
      "     0.24708374  0.27685535  0.31469119 -0.02468777  0.3784605   0.27143833\n",
      "     0.34404367  0.39987954]]\n",
      "\n",
      "  [[-0.22920002 -0.13672344 -0.30988768  0.30433753  0.04582956 -0.02326936\n",
      "    -0.00741017  0.09987469  0.21085915 -0.76750642 -0.5234158  -0.15107059\n",
      "     0.49486256 -0.18534914 -0.06077946  0.07774136  0.06825313  0.07461424\n",
      "     0.35467449 -1.00205696  0.18219779 -0.43974513 -0.28108868  0.19235854\n",
      "     0.00665231 -0.41361278  0.21675943  0.02912845 -0.1983604  -0.18309985\n",
      "     0.33050191 -0.52243155]]]\n",
      "\n",
      "\n",
      " [[[ 0.05952727  0.08323857  0.02420536 -0.29479116  0.27479443 -0.6066246\n",
      "     0.18317911 -0.08857599 -0.31766742  0.2967729   0.11962374  0.19396597\n",
      "    -0.58785975 -0.20716625 -0.21523967  0.05519104 -0.14424163  0.06008785\n",
      "    -0.27276909  0.52542996 -0.80677354  0.30591294 -0.44559431 -0.69881409\n",
      "     0.09449302 -0.73005086 -0.02197023  0.02283931  0.16950311 -0.39789161\n",
      "     0.02653069  0.07627544]]\n",
      "\n",
      "  [[-0.23521501  0.24588975  0.14953239  0.18760903  0.21153986 -0.26640609\n",
      "     0.51329851  0.34460559 -0.02405704  0.4750666   0.42866528 -0.3060106\n",
      "    -0.49718103  0.37359577  0.2847288  -0.00744476 -0.27251357  0.17031604\n",
      "    -0.35896242  0.38019177 -0.63104463 -0.16675058  0.22846431 -0.43770683\n",
      "     0.12087449 -0.53326666 -0.33760485  0.03432346  0.14239013  0.25791216\n",
      "    -0.09337354  0.39630941]]\n",
      "\n",
      "  [[-0.19830361  0.25474253  0.36808655  0.0913374  -0.66165179 -0.64854431\n",
      "     0.38144201 -0.13986588  0.22120549  0.09904992 -0.46772188 -0.17817248\n",
      "     0.21881013  0.02121044  0.29975808 -0.19558944  0.25380057  0.14234903\n",
      "    -0.11703214 -0.31696904 -0.22697169 -0.45760003  0.25334594 -0.42435446\n",
      "     0.09157654 -0.65562505  0.05640248 -0.0479014  -0.48566273  0.13541822\n",
      "    -0.37326881 -0.16481356]]]]\n"
     ]
    }
   ],
   "source": [
    "#attempt at printing convolved image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.squeeze(X_test[42]), cmap='gray')\n",
    "plt.show()\n",
    "weights, biases = m1.layers[0].get_weights()#two tensors\n",
    "print(type(weights))\n",
    "print(weights.shape)\n",
    "print(type(weights))\n",
    "print(biases.shape)\n",
    "#plt.imshow(weights[:, :, 0, 0], cmap='gray')\n",
    "#plt.show()\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "for i in range(0, 9):\n",
    "    ax = fig.add_subplot(3,3,i+1)\n",
    "    ax.imshow(weights[:, :, 0, i], cmap='gray')\n",
    "    \n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts on Kernel Patterns\n",
    "\n",
    "What immidiatly sticks out to me is that none of the kernels that i saw were heavily weighted for the center square, usually the corners had the highest weight. From what I remember of image processint this seems like it is valueing edge detection within the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,989,386\n",
      "Trainable params: 3,989,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0976 - acc: 0.9704 - val_loss: 0.0375 - val_acc: 0.9874\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0339 - acc: 0.9896 - val_loss: 0.0324 - val_acc: 0.9891\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0207 - acc: 0.9934 - val_loss: 0.0291 - val_acc: 0.9903\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0370 - val_acc: 0.9895\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0298 - val_acc: 0.9917\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0425 - val_acc: 0.9891\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0521 - val_acc: 0.9883\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 245s 4ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0517 - val_acc: 0.9900\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0425 - val_acc: 0.9915\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0524 - val_acc: 0.9901\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0605 - val_acc: 0.9898\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0765 - val_acc: 0.9888\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0736 - val_acc: 0.9886\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0668 - val_acc: 0.9886\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0725 - val_acc: 0.9872\n",
      "Test loss: 0.0725123223419\n",
      "Test accuracy: 0.9872\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       980\n",
      "          1       0.99      1.00      0.99      1135\n",
      "          2       0.98      0.99      0.99      1032\n",
      "          3       1.00      0.99      0.99      1010\n",
      "          4       0.98      0.99      0.99       982\n",
      "          5       0.98      0.99      0.98       892\n",
      "          6       1.00      0.99      0.99       958\n",
      "          7       0.98      0.98      0.98      1028\n",
      "          8       0.97      0.99      0.98       974\n",
      "          9       1.00      0.96      0.98      1009\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1130    2    0    0    2    1    0    0    0]\n",
      " [   2    0 1022    0    0    0    0    5    2    1]\n",
      " [   0    0    2  996    0    8    0    1    3    0]\n",
      " [   0    0    1    0  976    0    0    0    3    2]\n",
      " [   0    0    0    4    0  879    1    0    8    0]\n",
      " [   4    2    2    0    1    3  945    0    1    0]\n",
      " [   1    2    9    0    2    0    0 1012    2    0]\n",
      " [   3    0    2    1    2    0    0    2  963    1]\n",
      " [   0    3    0    0   15    5    0    7    6  973]]\n"
     ]
    }
   ],
   "source": [
    "#function for creating simple model\n",
    "#def train_cnn(xt, yt, xtrain, ytrain, c_depth, kern_sizes, padding, layers):# padding='valid' | 'same' and activation='relu'\n",
    "#    model = Sequential()\n",
    "#    input_shape = Input(shape=(height, width, depth))\n",
    "#    model.add(Conv2D(32, (kern_sizes[0], kern_sizes[0]), padding, activation='relu',\n",
    "#                 input_shape=input_shape))\n",
    "\n",
    "batch_size = 28 # in each iteration, we consider 28 training examples at once\n",
    "num_epochs = 15 # we iterate 200 times over the entire training set\n",
    "k_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 512 # the FC layer will have 512 neurons\n",
    "pad='same'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1)))#convolution one\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Conv2D(conv_depth_2, (k_size, k_size), activation='relu', input_shape=(28,28,1)))#convolution 2\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_size, activation='relu'))#neural network layer\n",
    "BatchNormalization()\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          epochs=num_epochs, verbose=1,\n",
    "          validation_data=(X_test, Y_test))#removed callbacks=[history]\n",
    "print_data(X_test, Y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts\n",
    "\n",
    "First of all 15 Epochs ended up being far to many rounds for (for my computer). I was rather astounded by how accurate this model was with digit prediction. \n",
    "\n",
    "### Future Plans\n",
    "\n",
    "In the future I would like to experiment more with number, size and type of layers within the model. Are there things that could be done to help the model improve it's accuracy when it comes to things like predicting nines as fours. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
