{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3 \n",
    "### Predicting Digits with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "\n",
    "X_train = idx2numpy.convert_from_file('train-images-idx3-ubyte')\n",
    "y_train = idx2numpy.convert_from_file('train-labels-idx1-ubyte')\n",
    "X_test = idx2numpy.convert_from_file('t10k-images-idx3-ubyte')\n",
    "y_test = idx2numpy.convert_from_file('t10k-labels-idx1-ubyte')\n",
    "X_train = np.reshape(X_train, (60000, 784))#flaten matricies\n",
    "X_test = np.reshape(X_test,(10000, 784))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "def print_data(y_text, y_predicted):\n",
    "    print(\"Accuracy\")\n",
    "    print(accuracy_score(y_test, y_predicted))\n",
    "    print(\"Classification\")\n",
    "    print(classification_report(y_test, y_predicted))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9175\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.93      0.88      0.90      1032\n",
      "          3       0.90      0.91      0.90      1010\n",
      "          4       0.93      0.93      0.93       982\n",
      "          5       0.90      0.85      0.88       892\n",
      "          6       0.94      0.95      0.94       958\n",
      "          7       0.93      0.92      0.92      1028\n",
      "          8       0.84      0.88      0.86       974\n",
      "          9       0.90      0.89      0.90      1009\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 958    0    0    4    0    3    5    2    6    2]\n",
      " [   0 1116    3    1    0    1    4    1    8    1]\n",
      " [   8   12  906   18    9    5   10   11   50    3]\n",
      " [   3    0   19  916    2   23    5   11   24    7]\n",
      " [   1    2    5    3  910    0   11    2   10   38]\n",
      " [  11    2    1   40   10  756   16    8   40    8]\n",
      " [   7    3    7    2    4   17  910    1    7    0]\n",
      " [   3    6   24    4    7    1    1  946    5   31]\n",
      " [   9   15    7   22   11   26    7   12  854   11]\n",
      " [   9    6    2   13   30    4    0   26   16  903]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "reg = LogisticRegression(solver = 'lbfgs')#code copied from previous lab\n",
    "reg.fit(X_train, y_train)\n",
    "y_predicted = reg.predict(X_test)\n",
    "\n",
    "print_data(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.8877\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95       980\n",
      "          1       0.99      0.97      0.98      1135\n",
      "          2       0.85      0.90      0.87      1032\n",
      "          3       0.87      0.83      0.85      1010\n",
      "          4       0.93      0.82      0.87       982\n",
      "          5       0.86      0.77      0.81       892\n",
      "          6       0.92      0.94      0.93       958\n",
      "          7       0.94      0.90      0.92      1028\n",
      "          8       0.78      0.88      0.83       974\n",
      "          9       0.80      0.91      0.85      1009\n",
      "\n",
      "avg / total       0.89      0.89      0.89     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 913    0    3    3    0   32   11    2   16    0]\n",
      " [   0 1097    8    4    0    3    3    1   18    1]\n",
      " [   3    0  926    9   10    0   16    7   55    6]\n",
      " [   2    0   70  841    0   33    1   19   35    9]\n",
      " [   1    0    3    1  810    3   20    1    6  137]\n",
      " [   5    0    6   82    2  686   14    2   77   18]\n",
      " [   9    2    6    0   15   12  899    1   14    0]\n",
      " [   1    4   46    6    6    1    0  929    4   31]\n",
      " [   7    1   22   12    4   25    8    6  854   35]\n",
      " [   5    6    1   10   26    6    1   17   15  922]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                    hidden_layer_sizes=(50), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_predicted = mlp.predict(X_test)\n",
    "\n",
    "print_data(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9453\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.97       980\n",
      "          1       0.98      0.98      0.98      1135\n",
      "          2       0.94      0.95      0.94      1032\n",
      "          3       0.94      0.93      0.93      1010\n",
      "          4       0.95      0.94      0.95       982\n",
      "          5       0.93      0.92      0.93       892\n",
      "          6       0.96      0.96      0.96       958\n",
      "          7       0.96      0.93      0.95      1028\n",
      "          8       0.90      0.94      0.92       974\n",
      "          9       0.92      0.93      0.92      1009\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 945    1    5    2    0    3   13    5    6    0]\n",
      " [   0 1112    4    3    0    1    2    1   12    0]\n",
      " [   4    3  979   11    6    2    4   10   10    3]\n",
      " [   1    2   14  942    0   19    2    4   18    8]\n",
      " [   0    1   10    0  921    3    6    3    7   31]\n",
      " [   5    1    0   26    1  820   12    1   21    5]\n",
      " [   6    4    5    0    3    9  923    3    5    0]\n",
      " [   3    4   18    7    5    3    1  955    5   27]\n",
      " [   5    0    8    9    7   11    3    4  918    9]\n",
      " [   3    6    3    7   24    7    0    7   14  938]]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                    hidden_layer_sizes=(100), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_predicted = mlp.predict(X_test)\n",
    "\n",
    "print_data(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9678\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.97      0.96      0.97      1032\n",
      "          3       0.96      0.97      0.96      1010\n",
      "          4       0.97      0.97      0.97       982\n",
      "          5       0.96      0.95      0.95       892\n",
      "          6       0.97      0.97      0.97       958\n",
      "          7       0.97      0.96      0.97      1028\n",
      "          8       0.96      0.95      0.96       974\n",
      "          9       0.95      0.96      0.96      1009\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 965    0    2    2    1    2    3    2    2    1]\n",
      " [   0 1120    3    2    0    2    2    3    3    0]\n",
      " [   5    3  994    6    4    0    2    7    9    2]\n",
      " [   1    0    3  980    0    9    0    3    5    9]\n",
      " [   1    0    5    0  952    1    2    4    2   15]\n",
      " [   4    0    2   16    2  848    8    1    4    7]\n",
      " [   4    2    2    1    6   11  927    1    4    0]\n",
      " [   1    3   10    3    3    0    0  991    4   13]\n",
      " [   2    1    3   14    4    7    5    3  929    6]\n",
      " [   0    4    1    2   11    5    2    8    4  972]]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                    hidden_layer_sizes=(400), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_predicted = mlp.predict(X_test)\n",
    "\n",
    "print_data(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9654\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98       980\n",
      "          1       0.99      0.99      0.99      1135\n",
      "          2       0.96      0.96      0.96      1032\n",
      "          3       0.95      0.96      0.96      1010\n",
      "          4       0.97      0.96      0.96       982\n",
      "          5       0.95      0.96      0.96       892\n",
      "          6       0.97      0.97      0.97       958\n",
      "          7       0.97      0.96      0.97      1028\n",
      "          8       0.96      0.96      0.96       974\n",
      "          9       0.95      0.94      0.95      1009\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 959    0    3    0    2    5    2    6    3    0]\n",
      " [   0 1121    5    3    0    1    2    0    2    1]\n",
      " [   7    1  989   12    3    2    4    7    7    0]\n",
      " [   0    1   14  974    1    6    0    4    8    2]\n",
      " [   2    0    5    0  941    0    8    0    2   24]\n",
      " [   2    0    1   13    0  859    5    0    6    6]\n",
      " [   6    3    0    0    7    5  932    0    5    0]\n",
      " [   2    3    9    6    0    0    0  991    4   13]\n",
      " [   5    0    4    7    3    8    2    5  938    2]\n",
      " [   2    3    0    9   17   14    1   10    3  950]]\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                    hidden_layer_sizes=(100, 50), random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_predicted = mlp.predict(X_test)\n",
    "\n",
    "print_data(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "#### Best\n",
    "\n",
    "With the current trial runs, the 400 layer neural network actually turned out to be the best with an accuracy of 96.78%. However, the two layer neural network was almost just as good with an accuracy of 96.54%\n",
    "\n",
    "#### Worst\n",
    "\n",
    "As I would have guessed the worst accuracy was the 50 node neural net. Just looking at that setup it did not seem to have enough nodes to be able to do a decent job at learning the data.\n",
    "\n",
    "### F1 Score\n",
    "\n",
    "#### Best \n",
    "\n",
    "The best F1 score turned out to be a tie of .97 between the two layer network and the 400 node network. Since the F1 score take precision into account as well, it is actually a better measure of the quality of a model. Thus i find it very interesting that these two different models produced similarly effective models.\n",
    "\n",
    "#### Worst\n",
    "\n",
    "As before the 50 node neural network had the worst F1 score. We can conclude from this data that this model is objectivly the worst model we've attempted so far.\n",
    "\n",
    "### Shape of the Data\n",
    "\n",
    "The data we used for training this model had 60000 elements with 784 pixels per element. For each of our neural networks we would then have 784 input nodes.\n",
    "\n",
    "### Why LBFGS\n",
    "\n",
    "In short we are using LBFGS to optimize our training time. We do this because the training time for these networks can be extremely high to the point that we would spend too much time running the model versus actually studying the data and the result.\n",
    "LBFGS is an optimization on BFGS. BFGS stores all data points for matrix multiplication whereas LBFGS stores vectors that imply the original data points and is thus able to simplify the calculation and run the training algorithm much quicker.\n",
    "\n",
    "### Afterthoughts\n",
    "\n",
    "Neural networks very quickly become a black box. Any typical human being can't take a quick glance at a neural network and say exactly why it came to one conclusion for a peice of data versus another. We can however make some general assumptions about what is happening internally. For instance, THe accuracy, and F1 score of the models increased as the number of nodes increased. With this we can conlude that having too few nodes for a dataset can hinder the performance of a model. There is a limit to this as we saw, I can't just keep adding nodes to a model to increase the accuracy. There was a diminishing return to increasing nodes having a positive result on the outcome. With the limited trial runs it is hard to make a judgement as to why the two layer network worked so comparably to the 400 node model. My best guess would be that the additional layer adds more room for the model to attempt to interpret the data. \n",
    "Some potential trials I could run to gain a better grasp on this would be doing a three and four layer run. I would also like to play with having larger first, last, and middle layers to see how that affects the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#softmax\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run() got multiple values for argument 'feed_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fabb68aca991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#print_data(act, pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: run() got multiple values for argument 'feed_dict'"
     ]
    }
   ],
   "source": [
    "#softmax model\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)# create model\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "predicted = tf.argmax(y, 1)\n",
    "actual = tf.argmax(y_, 1)\n",
    "print(type(predicted))\n",
    "pred, act = sess.run(predicted, actual, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "#print_data(act, pred)\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
