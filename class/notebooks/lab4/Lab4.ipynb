{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4 Convolution\n",
    "\n",
    "### Predicting Digits\n",
    "\n",
    "Notes on M.L. Libraries\n",
    "\n",
    "Potential libraries to use:\n",
    "\n",
    "Theano\n",
    "\n",
    "Tensorflow, Google\n",
    "\n",
    "    could remake this in notebook for assignment:\n",
    "    \n",
    "    https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "    \n",
    "Torch/Pytorch, Facebook\n",
    "\n",
    "CNTK(gluon)\n",
    "\n",
    "Keras\n",
    "\n",
    "    pip install --update keras\n",
    "    \n",
    "(more options in c++/cuda)\n",
    "\n",
    "For this project I will be using Keras for data training. For a decent introduction to keras see: https://yashk2810.github.io/Applying-Convolutional-Neural-Network-on-the-MNIST-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model # basic class for specifying and training a neural network\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "num_train, height, width, depth = X_train.shape # there are 50000 training examples\n",
    "num_test = X_test.shape[0] # there are 10000 test examples\n",
    "num_classes = np.unique(y_train).shape[0] # there are 10 image classes\n",
    "\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train/= 255 # Normalise data to [0, 1] range\n",
    "X_test/= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes) # One-hot encode the labels\n",
    "\n",
    "inp = Input(shape=(height, width, depth)) # depth goes last in TensorFlow back-end\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def print_data(testx, testy, m):#m for model\n",
    "    score = m.evaluate(testx, testy, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])#print accuracy    \n",
    "    predictions = model.predict_classes(testx)\n",
    "    Y_t = np.argmax(testy, axis=1)\n",
    "    print(precision_recall_fscore_support(Y_t, predictions))\n",
    "    print(\"Classification\")\n",
    "    print(classification_report(Y_t, predictions))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(Y_t, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                346176    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 347,146\n",
      "Trainable params: 347,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 39s 656us/step - loss: 0.1592 - acc: 0.9537 - val_loss: 0.0674 - val_acc: 0.9782\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 40s 667us/step - loss: 0.0554 - acc: 0.9829 - val_loss: 0.0491 - val_acc: 0.9847\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 38s 631us/step - loss: 0.0374 - acc: 0.9886 - val_loss: 0.0475 - val_acc: 0.9847\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 38s 637us/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0447 - val_acc: 0.9859\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 40s 668us/step - loss: 0.0181 - acc: 0.9943 - val_loss: 0.0469 - val_acc: 0.9851\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 40s 661us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0463 - val_acc: 0.9869\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 40s 663us/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0548 - val_acc: 0.9848\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 40s 668us/step - loss: 0.0077 - acc: 0.9973 - val_loss: 0.0522 - val_acc: 0.9869\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 42s 705us/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0580 - val_acc: 0.9861\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 41s 685us/step - loss: 0.0057 - acc: 0.9980 - val_loss: 0.0689 - val_acc: 0.9842\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 37s 623us/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0572 - val_acc: 0.9883\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 37s 609us/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0587 - val_acc: 0.9876\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 37s 610us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0643 - val_acc: 0.9879\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 39s 653us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0654 - val_acc: 0.9871\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 38s 639us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0709 - val_acc: 0.9848\n",
      "Test loss: 0.0709165336586\n",
      "Test accuracy: 0.9848\n",
      "(array([ 0.98985801,  0.99384345,  0.98269231,  0.995005  ,  0.97991968,\n",
      "        0.97993311,  0.99578504,  0.9844358 ,  0.97371082,  0.99590583]), array([ 0.99591837,  0.99559471,  0.99031008,  0.98613861,  0.99389002,\n",
      "        0.98542601,  0.98643006,  0.9844358 ,  0.98870637,  0.96432111]), array([ 0.99287894,  0.99471831,  0.98648649,  0.99055196,  0.98685541,\n",
      "        0.98267188,  0.99108547,  0.9844358 ,  0.9811513 ,  0.97985901]), array([ 980, 1135, 1032, 1010,  982,  892,  958, 1028,  974, 1009]))\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       980\n",
      "          1       0.99      1.00      0.99      1135\n",
      "          2       0.98      0.99      0.99      1032\n",
      "          3       1.00      0.99      0.99      1010\n",
      "          4       0.98      0.99      0.99       982\n",
      "          5       0.98      0.99      0.98       892\n",
      "          6       1.00      0.99      0.99       958\n",
      "          7       0.98      0.98      0.98      1028\n",
      "          8       0.97      0.99      0.98       974\n",
      "          9       1.00      0.96      0.98      1009\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1130    2    0    0    2    1    0    0    0]\n",
      " [   2    0 1022    0    0    0    0    5    2    1]\n",
      " [   0    0    2  996    0    8    0    1    3    0]\n",
      " [   0    0    1    0  976    0    0    0    3    2]\n",
      " [   0    0    0    4    0  879    1    0    8    0]\n",
      " [   4    2    2    0    1    3  945    0    1    0]\n",
      " [   1    2    9    0    2    0    0 1012    2    0]\n",
      " [   3    0    2    1    2    0    0    2  963    1]\n",
      " [   0    3    0    0   15    5    0    7    6  973]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 28 # in each iteration, we consider 28 training examples at once\n",
    "num_epochs = 15 # we iterate 200 times over the entire training set\n",
    "k_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 512 # the FC layer will have 512 neurons\n",
    "pad='same'\n",
    "\n",
    "m1 = Sequential()\n",
    "m1.add(Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1)))\n",
    "BatchNormalization(axis=-1)\n",
    "m1.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "m1.add(Flatten())\n",
    "m1.add(Dense(conv_depth_2, activation='relu'))#neural network layer\n",
    "BatchNormalization()\n",
    "m1.add(Dense(num_classes, activation='softmax'))\n",
    "m1.summary()\n",
    "m1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "m1.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          epochs=num_epochs, verbose=1,\n",
    "          validation_data=(X_test, Y_test))#removed callbacks=[history]\n",
    "\n",
    "print_data(X_test, Y_test, m1)\n",
    "#unused code from an example i found\n",
    "## Conv [32] -> Conv [32] -> Pool (with dropout on the pooling layer)\n",
    "#conv_1 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(inp)\n",
    "#conv_2 = Convolution2D(conv_depth_1, (kernel_size, kernel_size), padding='same', activation='relu')(conv_1)\n",
    "#pool_1 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_2)\n",
    "#drop_1 = Dropout(drop_prob_1)(pool_1)\n",
    "## Conv [64] -> Conv [64] -> Pool (with dropout on the pooling layer)\n",
    "#conv_3 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(drop_1)\n",
    "#conv_4 = Convolution2D(conv_depth_2, (kernel_size, kernel_size), padding='same', activation='relu')(conv_3)\n",
    "#pool_2 = MaxPooling2D(pool_size=(pool_size, pool_size))(conv_4)\n",
    "#drop_2 = Dropout(drop_prob_1)(pool_2)\n",
    "## Now flatten to 1D, apply FC -> ReLU (with dropout) -> softmax\n",
    "#flat = Flatten()(drop_2)\n",
    "#hidden = Dense(hidden_size, activation='relu')(flat)\n",
    "#drop_3 = Dropout(drop_prob_2)(hidden)\n",
    "#out = Dense(num_classes, activation='softmax')(drop_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Run\n",
    "\n",
    "For this model I used once convolutional layer with 32 kernels, and one fully connected neural network layer that fed into a softmax output layer. The model came up with a 98.48% accuracy. The model was most often wrong when it came to the digit 9 being predicted as a 4, which to be honest seems like an almost human mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "[ array([[[[ 0.08820431, -0.44641867, -0.88097876, -0.07507395, -0.40566126,\n",
      "           0.06497961,  0.1707484 , -0.01209065, -0.27897948, -0.14978291,\n",
      "          -0.30384451,  0.36983857,  0.08988312,  0.18144797,  0.02842912,\n",
      "           0.30834857, -0.38621953, -0.66700631, -0.26434869, -0.91094416,\n",
      "          -0.3520191 , -0.5449453 ,  0.19656755,  0.18398382,  0.27702123,\n",
      "          -0.59177518, -0.45021373,  0.33859068, -0.17936404,  0.18795776,\n",
      "           0.37416011, -0.99000853]],\n",
      "\n",
      "        [[ 0.00494679, -0.34724867, -0.51450425, -0.05088293, -0.31316292,\n",
      "           0.31603613,  0.15382288,  0.65434849,  0.18235071,  0.16415694,\n",
      "          -0.39756277, -0.10513358, -0.4093996 ,  0.31778014,  0.26132372,\n",
      "           0.24170583,  0.17828439, -0.21541643, -0.57579166, -0.02866375,\n",
      "           0.39694309,  0.25372797, -0.20952141,  0.18458132,  0.42046866,\n",
      "          -0.0938383 ,  0.14909534,  0.04610151,  0.00885721,  0.15340136,\n",
      "          -0.17662215, -0.42633432]],\n",
      "\n",
      "        [[ 0.31910747, -0.48851898, -0.59900224,  0.17854139, -0.06652834,\n",
      "          -0.06256513, -0.30607072,  0.41963992,  0.64760309,  0.28887081,\n",
      "          -0.57928091, -0.44292128, -0.30978483, -0.44046721,  0.19610117,\n",
      "          -0.33464438,  0.16114381,  0.28174207, -0.48727185,  0.32547137,\n",
      "          -0.04020598,  0.22283593, -0.10894819, -0.10889798, -0.71095884,\n",
      "          -0.04591331,  0.07939311, -0.72636515,  0.20146433, -0.00365971,\n",
      "           0.0263185 , -0.28059697]]],\n",
      "\n",
      "\n",
      "       [[[-0.03427936, -0.21724005, -0.04473332, -0.46177092, -0.18259163,\n",
      "           0.19611721,  0.0315191 , -0.76479584, -0.52289248,  0.24396582,\n",
      "           0.42343971,  0.07511138,  0.27947176, -0.35607368,  0.1379554 ,\n",
      "          -0.1151838 , -0.20711085, -0.08949107, -0.84067661, -0.579449  ,\n",
      "          -0.2749472 ,  0.25760436,  0.08575228, -0.06194454,  0.34989229,\n",
      "           0.02900305,  0.45785758,  0.28006548,  0.26283225, -0.1603038 ,\n",
      "           0.10754735,  0.12202755]],\n",
      "\n",
      "        [[-0.66052777,  0.06002522,  0.19561692,  0.31086132,  0.2772291 ,\n",
      "           0.05029619,  0.24829127,  0.04330701, -0.21843484, -0.11545622,\n",
      "           0.52457935, -0.07606965,  0.03362511,  0.19893001,  0.50460553,\n",
      "           0.24549112, -0.07448076,  0.06714851, -0.09479657,  0.11853395,\n",
      "           0.4146136 ,  0.16028517,  0.05457164, -0.28004777,  0.15323246,\n",
      "           0.44745141, -0.01004405,  0.18122907,  0.32910466,  0.2633248 ,\n",
      "          -0.19426757,  0.01749231]],\n",
      "\n",
      "        [[ 0.04954863, -0.1275351 ,  0.39120108, -0.12410641,  0.37796968,\n",
      "          -0.78311872,  0.22095212, -0.18941009,  0.24987397, -0.37355047,\n",
      "          -0.17820519, -0.19238274, -0.42710021,  0.0393809 , -0.05931429,\n",
      "          -0.01413943,  0.12346455,  0.09245144,  0.32828456,  0.35685614,\n",
      "          -0.32390004, -0.21914145, -0.33499235,  0.24420892, -0.53670949,\n",
      "           0.21879296, -0.13532552, -0.61166638,  0.08431853,  0.49196872,\n",
      "          -0.41636404, -1.08524346]]],\n",
      "\n",
      "\n",
      "       [[[ 0.40866214,  0.38803431, -0.18294995, -0.50736797,  0.0963501 ,\n",
      "          -0.43810719, -0.51405972, -0.59244782, -0.56292278, -0.47147232,\n",
      "          -0.10986383, -0.00343582,  0.22403042, -0.04484842, -0.85955411,\n",
      "          -0.49222711,  0.20377876,  0.05078489, -0.14326745, -0.48416793,\n",
      "           0.11388616,  0.09450886, -0.11260009,  0.12868458, -0.29976016,\n",
      "           0.01451625, -0.09413152,  0.24749826, -0.15950224, -0.36000356,\n",
      "           0.00433624,  0.56304425]],\n",
      "\n",
      "        [[-0.31281996,  0.38524544,  0.28037256,  0.47272554,  0.08765654,\n",
      "          -0.47434068, -0.18130334, -0.44994405, -0.69798923, -0.07686062,\n",
      "           0.1339242 ,  0.24888165,  0.39767152,  0.09425472, -0.38219437,\n",
      "           0.10483959,  0.25031751,  0.16080721,  0.24488661,  0.09908983,\n",
      "           0.29280493,  0.12322894,  0.06668703, -0.27459848, -0.78717828,\n",
      "           0.09646549, -0.22314806, -0.09919814, -0.45408645, -0.37750494,\n",
      "           0.15231644,  0.46753776]],\n",
      "\n",
      "        [[ 0.19243181,  0.18459062,  0.13056172, -0.07168466, -0.25695318,\n",
      "          -0.01566645,  0.22464406, -1.01989043, -0.33017731, -0.28575268,\n",
      "          -0.14875072,  0.38633713, -0.06064335,  0.13435657, -0.75791627,\n",
      "           0.28989333, -0.21123816,  0.02056622,  0.32343802,  0.12936485,\n",
      "          -0.29726928, -0.61520034,  0.25065842,  0.22121081, -0.51891112,\n",
      "          -0.68413168,  0.02096555, -0.75489295, -0.23374517, -0.38871497,\n",
      "           0.33786622, -0.31213048]]]], dtype=float32)\n",
      " array([-0.18012103, -0.10368036, -0.0333303 , -0.18985406, -0.12225397,\n",
      "       -0.04365785, -0.34795588, -0.01432529, -0.0544197 , -0.07896401,\n",
      "       -0.02087353, -0.49221808, -0.18299453, -0.24376552, -0.08329005,\n",
      "       -0.32050654, -0.28928572, -0.27317926, -0.03616527, -0.14106883,\n",
      "       -0.12100135, -0.16835709, -0.28639349, -0.27825233, -0.02092381,\n",
      "       -0.07139526, -0.11499885, -0.19073988, -0.08216535, -0.11266224,\n",
      "       -0.40344656, -0.02846981], dtype=float32)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-732d93373055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#tmp = np.expand_dims(tmp, axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#t2 = np.array(tmp, dtype=float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/MachineLearning/class/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3081\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MachineLearning/class/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1708\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1709\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1710\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MachineLearning/class/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5192\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5194\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5195\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MachineLearning/class/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    598\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    599\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3047be6a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attempt at printing convolved image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(np.squeeze(X_test[42]), cmap='gray')\n",
    "\n",
    "#con = Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1))\n",
    "tmp = m1.layers[0].get_weights()\n",
    "np_tmp = np.asarray(tmp)\n",
    "np_tmp = np.squeeze(np_tmp)\n",
    "print(np_tmp.shape)\n",
    "print(np_tmp)\n",
    "#tmp = np.expand_dims(tmp, axis=0)\n",
    "#t2 = np.array(tmp, dtype=float)\n",
    "plt.imshow(np_tmp, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code edited from: https://github.com/yashk2810/Visualization-of-Convolutional-Layers/blob/master/Visualizing%20Filters%20Python3%20Theano%20Backend.ipynb\n",
    "def visualize_layer(layer, modl, example_image):\n",
    "    inputs = [K.learning_phase()] + modl.inputs\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(example_image)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "    \n",
    "    n = convolutions.shape[0]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "    \n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(len(convolutions)):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "visualize_layer() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f6d4e2603be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvisualize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: visualize_layer() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "X_example = X_test[42]\n",
    "X_example = np.expand_dims(X_example, axis=0)\n",
    "visualize_layer(m1.layers[0], m1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               3965440   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,989,386\n",
      "Trainable params: 3,989,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0976 - acc: 0.9704 - val_loss: 0.0375 - val_acc: 0.9874\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0339 - acc: 0.9896 - val_loss: 0.0324 - val_acc: 0.9891\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0207 - acc: 0.9934 - val_loss: 0.0291 - val_acc: 0.9903\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0370 - val_acc: 0.9895\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0298 - val_acc: 0.9917\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 199s 3ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0425 - val_acc: 0.9891\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0073 - acc: 0.9974 - val_loss: 0.0521 - val_acc: 0.9883\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 245s 4ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0517 - val_acc: 0.9900\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0425 - val_acc: 0.9915\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0524 - val_acc: 0.9901\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0605 - val_acc: 0.9898\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0765 - val_acc: 0.9888\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0736 - val_acc: 0.9886\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0668 - val_acc: 0.9886\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0725 - val_acc: 0.9872\n",
      "Test loss: 0.0725123223419\n",
      "Test accuracy: 0.9872\n",
      "Classification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       980\n",
      "          1       0.99      1.00      0.99      1135\n",
      "          2       0.98      0.99      0.99      1032\n",
      "          3       1.00      0.99      0.99      1010\n",
      "          4       0.98      0.99      0.99       982\n",
      "          5       0.98      0.99      0.98       892\n",
      "          6       1.00      0.99      0.99       958\n",
      "          7       0.98      0.98      0.98      1028\n",
      "          8       0.97      0.99      0.98       974\n",
      "          9       1.00      0.96      0.98      1009\n",
      "\n",
      "avg / total       0.99      0.99      0.99     10000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 976    0    0    0    0    0    2    1    1    0]\n",
      " [   0 1130    2    0    0    2    1    0    0    0]\n",
      " [   2    0 1022    0    0    0    0    5    2    1]\n",
      " [   0    0    2  996    0    8    0    1    3    0]\n",
      " [   0    0    1    0  976    0    0    0    3    2]\n",
      " [   0    0    0    4    0  879    1    0    8    0]\n",
      " [   4    2    2    0    1    3  945    0    1    0]\n",
      " [   1    2    9    0    2    0    0 1012    2    0]\n",
      " [   3    0    2    1    2    0    0    2  963    1]\n",
      " [   0    3    0    0   15    5    0    7    6  973]]\n"
     ]
    }
   ],
   "source": [
    "#function for creating simple model\n",
    "#def train_cnn(xt, yt, xtrain, ytrain, c_depth, kern_sizes, padding, layers):# padding='valid' | 'same' and activation='relu'\n",
    "#    model = Sequential()\n",
    "#    input_shape = Input(shape=(height, width, depth))\n",
    "#    model.add(Conv2D(32, (kern_sizes[0], kern_sizes[0]), padding, activation='relu',\n",
    "#                 input_shape=input_shape))\n",
    "\n",
    "batch_size = 28 # in each iteration, we consider 28 training examples at once\n",
    "num_epochs = 15 # we iterate 200 times over the entire training set\n",
    "k_size = 3 # we will use 3x3 kernels throughout\n",
    "pool_size = 2 # we will use 2x2 pooling throughout\n",
    "conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "drop_prob_2 = 0.5 # dropout in the FC layer with probability 0.5\n",
    "hidden_size = 512 # the FC layer will have 512 neurons\n",
    "pad='same'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(conv_depth_1, (k_size, k_size), activation='relu', input_shape=(28,28,1)))#convolution one\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Conv2D(conv_depth_2, (k_size, k_size), activation='relu', input_shape=(28,28,1)))#convolution 2\n",
    "BatchNormalization(axis=-1)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_size, activation='relu'))#neural network layer\n",
    "BatchNormalization()\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=batch_size,\n",
    "          epochs=num_epochs, verbose=1,\n",
    "          validation_data=(X_test, Y_test))#removed callbacks=[history]\n",
    "print_data(X_test, Y_test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
